%% Average Distance Between Points Using GAIL

%% A simple, concrete example  
% Recall again the problem of determining the average distance between two
% points in a unit square.  The true answer is a 4-dimensional integral
% 
% \[ \mu = \int_{[0,1]^2 \times [0,1]^2} \sqrt{(x_1-y_1)^2 + (x_2-y_2)^2}
% \, {\rm d}x_1 \, {\rm d}x_2 \, {\rm d}y_1 \, {\rm d}y_2 \]
% 
% We talked about how to compute the answer using Monte Carlo methods.
% First we define a mean distance function as follows

distfun = @(n) sqrt(sum((rand(n,2)  - rand(n,2)).^2,2));

%% 
% To approximate the answer, \(\mu\), we may use the sample mean with |n =
% 1e6| points.  This is the Monte Carlo method

tic, meandist = mean(distfun(1e6)), toc

%%
% The problem is that we do not yet know how accurate our answer is.

%% Guaranteed Automatic Integration Library (GAIL)
% Several of us have been developing Monte Carlo methods that adaptively
% determine the sample size (|n|) to fit a pre-defined criterion.  One of
% these routines is |meanMC_g|.  It is described in 
%
% F. J. Hickernell, L. Jiang, Y. Liu, and A. B. Owen, Guaranteed
% Conservative Fixed Width Confidence Intervals Via Monte Carlo
% Sampling, _Monte Carlo and Quasi-Monte Carlo Methods 2012_ (J. Dick, F.
% Y. Kuo, G. W. Peters, and I. H. Sloan, eds.), 2014, p. 105-128.
%
% To determine \(\mu\) with an absolute error tolerance of 0.02, we use the
% command

tic, meandist = meanMC_g(distfun,0.02,0), toc

%%
% where 0.2 represents the absolute error tolerance and 0 represents the
% relative error tolerance.  The algorithm |meanMC_g| guarantees that 
%
% \[ \mathbb{P}[|\mu - \texttt{meandist}| \le 0.02] \ge 99\% \]
%
% Note that the time required by |meanMC_g| is less than that required by
% taking the mean of 1e6 samples.  To find out how many samples |meanMC_g|
% actually used, we may try

[meandist,output] = meanMC_g(distfun,0.02,0)

%%
% The value of |output.ntot| is the total number of samples used.

%% The quasi-Monte Carlo algorithm 
% The points generated by |rand| are independent and identically
% distributed (IID). This means that every point knows nothing about the
% other. Here are 128 IID points plotted

set(0,'defaultaxesfontsize',20) %make axis labels a larger font
xrand=rand(128,2);
plot(xrand(:,1),xrand(:,2),'b.','markersize',30)
axis('square')

%%
% Because the points are IID, there are gaps and clusters.
%
% Another kind of points, called Sobol' points, are _more_ evenly spaced
% than IID points.  Here are 128 Sobol' points

xsob = net(scramble(sobolset(2),'MatousekAffineOwen'),128);
plot(xsob(:,1),xsob(:,2),'b.','markersize',30)
axis('square')

%%
% Can you see the difference?
%
% We also have an algorithm |cubSobol_g| that works like |meanMC_g|, except
% that it uses Sobol' points.  Also, one needs to define the output as a
% function of the input \(\boldsymbol{x} \in [0,1]^4\) rather than the
% number of samples:

distfunx = @(x) sqrt(sum((x(:,1:2)  - x(:,3:4)).^2,2));
tic, meandist = cubSobol_g(distfunx,[zeros(1,4); ones(1,4)],'uniform', 0.02,0), toc

%%
% Because the error tolerance is not too small, the advantage of |cubSobol_g|
% over |meanMC_g| may not be apparent, but if we choose a smaller
% tolerance, then one can see the speed-up that is possible.

tic, meandist = meanMC_g(distfun,0.0001,0), toc
tic, meandist = cubSobol_g(distfunx,[zeros(1,4); ones(1,4)],'uniform', 0.0001,0), toc

%% Assignment due May 27, 2016
% * Modify this MATLAB m-file so that it computes the average distance
% between two points in a |d|-dimensional unit cube, i.e., generalize from
% |d = 2| to arbitrary |d|.
% * Try the other quasi-Monte Carlo algorithm |cubLattice_g|.


